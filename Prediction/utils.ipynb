{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe73599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "utils.py - Common helper functions for ascending aortic aneurysm research project\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8d3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from typing import Dict, List, Tuple, Union\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import label_binarize, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, ConfusionMatrixDisplay, \n",
    "    roc_curve, auc, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dd157",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "Data Loading & Preprocessing\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11247ca",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_data(file_paths: Dict[str, str]) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Load multiple CSV files into a dictionary of DataFrames\n",
    "    \n",
    "    Args:\n",
    "        file_paths: Dictionary of {name: file_path} pairs\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of {name: DataFrame} pairs\n",
    "    \"\"\"\n",
    "    return {k: pd.read_csv(v) for k, v in file_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3799c9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def clean_feature_df(df: pd.DataFrame, suffix: str = \"\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean and rename feature columns in a radiomics DataFrame\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        suffix: Suffix to add to column names\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    general_exclude_cols = [\"Image\", \"Mask\"] + [\n",
    "        col for col in df.columns if \"diagnostics\" in col\n",
    "    ]\n",
    "    df = df.drop(\n",
    "        columns=[col for col in df.columns if col in general_exclude_cols],\n",
    "        errors='ignore'\n",
    "    )\n",
    "    return df.rename(\n",
    "        columns={col: col + suffix for col in df.columns if col != \"ID\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237dc567",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def merge_dataframes(df_dict: Dict[str, pd.DataFrame], \n",
    "                    selected_keys: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Merge multiple DataFrames on the 'ID' column\n",
    "    \n",
    "    Args:\n",
    "        df_dict: Dictionary of DataFrames\n",
    "        selected_keys: List of keys to merge\n",
    "        \n",
    "    Returns:\n",
    "        Merged DataFrame\n",
    "    \"\"\"\n",
    "    return reduce(\n",
    "        lambda left, right: pd.merge(left, right, on=\"ID\", how=\"left\"),\n",
    "        [df_dict[k] for k in selected_keys]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5770989",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "Feature Engineering\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0de04",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def categorize_diameter(value: float) -> int:\n",
    "    \"\"\"\n",
    "    Categorize aortic diameter into clinical groups\n",
    "    \n",
    "    Args:\n",
    "        value: Max diameter in mm\n",
    "        \n",
    "    Returns:\n",
    "        0 (<40mm), 1 (40-45mm), 2 (45-50mm), or 3 (≥50mm)\n",
    "    \"\"\"\n",
    "    if value < 40:\n",
    "        return 0\n",
    "    elif value < 45:\n",
    "        return 1\n",
    "    elif value < 50:\n",
    "        return 2\n",
    "    return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901c75c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def filter_feature_types(df: pd.DataFrame, \n",
    "                        feature_type: str = \"all\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter features by type (shape+measure vs all)\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        feature_type: \"shape+measure\" or \"all\"\n",
    "        \n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    if feature_type == \"shape+measure\":\n",
    "        texture_keywords = [\n",
    "            \"firstorder\", \"glcm\", \"glrlm\", \n",
    "            \"glszm\", \"gldm\", \"ngtdm\"\n",
    "        ]\n",
    "        return df[[\n",
    "            col for col in df.columns \n",
    "            if not any(key in col.lower() for key in texture_keywords) \n",
    "            or col in [\"ID\", \"Label\", \"max_diameter\"]\n",
    "        ]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a284f",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "Model Evaluation\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383f542",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier(\n",
    "    model: xgb.XGBClassifier,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series\n",
    ") -> Tuple[float, np.ndarray, Dict[int, List]]:\n",
    "    \"\"\"\n",
    "    Evaluate classifier performance\n",
    "    \n",
    "    Args:\n",
    "        model: Trained classifier\n",
    "        X_test: Test features\n",
    "        y_test: True labels\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (accuracy, confusion_matrix, roc_curves)\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1, 2, 3])\n",
    "    \n",
    "    y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "    roc_curves = {}\n",
    "    for i in range(4):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_pred_proba[:, i])\n",
    "        roc_curves[i] = (fpr, tpr, auc(fpr, tpr))\n",
    "    \n",
    "    return accuracy, cm, roc_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5f6413",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_regressor(\n",
    "    model: xgb.XGBRegressor,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: pd.Series\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate regressor performance\n",
    "    \n",
    "    Args:\n",
    "        model: Trained regressor\n",
    "        X_test: Test features\n",
    "        y_test: True values\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (rmse, mae, r2)\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    return (\n",
    "        np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        mean_absolute_error(y_test, y_pred),\n",
    "        r2_score(y_test, y_pred)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ebbb6c",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "Visualization\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773575a3",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(\n",
    "    cm: np.ndarray,\n",
    "    title: str = \"Confusion Matrix\",\n",
    "    labels: List[str] = None,\n",
    "    save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    \n",
    "    Args:\n",
    "        cm: Confusion matrix array\n",
    "        title: Plot title\n",
    "        labels: List of class labels\n",
    "        save_path: Path to save figure (optional)\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = [\"< 40 mm\", \"40 - 45 mm\", \"45 - 50 mm\", \"≥ 50 mm\"]\n",
    "    \n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=cm,\n",
    "        display_labels=labels\n",
    "    )\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".0f\")\n",
    "    plt.title(title)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=700, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c74339",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_roc_curves(\n",
    "    roc_data: Dict[int, List],\n",
    "    title: str = \"ROC Curves\",\n",
    "    save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot ROC curves for all classes\n",
    "    \n",
    "    Args:\n",
    "        roc_data: Dictionary of ROC curve data\n",
    "        title: Plot title\n",
    "        save_path: Path to save figure (optional)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for class_id, (fpr, tpr, roc_auc) in roc_data.items():\n",
    "        plt.plot(fpr, tpr, label=f\"Class {class_id} (AUROC = {roc_auc:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=700, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115f44d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def plot_feature_importance(\n",
    "    model: Union[xgb.XGBClassifier, xgb.XGBRegressor],\n",
    "    importance_type: str = \"weight\",\n",
    "    title: str = \"Feature Importance\",\n",
    "    max_features: int = 10,\n",
    "    save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot feature importance\n",
    "    \n",
    "    Args:\n",
    "        model: Trained XGBoost model\n",
    "        importance_type: Type of importance (\"weight\", \"gain\", \"cover\")\n",
    "        title: Plot title\n",
    "        max_features: Number of top features to show\n",
    "        save_path: Path to save figure (optional)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    xgb.plot_importance(\n",
    "        model,\n",
    "        importance_type=importance_type,\n",
    "        max_num_features=max_features,\n",
    "        title=title\n",
    "    )\n",
    "    plt.grid(False)\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=700, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da2168",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "Model Configuration\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5f3ec4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_xgb_classifier() -> xgb.XGBClassifier:\n",
    "    \"\"\"Get configured XGBoost classifier\"\"\"\n",
    "    return xgb.XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        num_class=4,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=1000,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.9,\n",
    "        min_child_weight=2,\n",
    "        gamma=0.1,\n",
    "        random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3d45d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_regressor() -> xgb.XGBRegressor:\n",
    "    \"\"\"Get configured XGBoost regressor\"\"\"\n",
    "    return xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        eval_metric=\"rmse\",\n",
    "        max_depth=6,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=1000,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.9,\n",
    "        min_child_weight=2,\n",
    "        gamma=0.1,\n",
    "        random_state=42\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
