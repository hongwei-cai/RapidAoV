{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eacb2d98",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# PCA Analysis\n",
    "## Dimensionality Reduction for Aortic Features\n",
    "\n",
    "This notebook demonstrates the use of Principal Component Analysis (PCA) for dimensionality reduction on aortic profile data. The goal is to reduce the complexity of the data while retaining the most important features for classification and visualization.\n",
    "\n",
    "### Objectives:\n",
    "1. Load and preprocess aortic profile data.\n",
    "2. Perform PCA to reduce dimensionality.\n",
    "3. Visualize the PCA-transformed data.\n",
    "4. Evaluate classification performance using PCA-transformed features.\n",
    "5. Provide an interactive interface for PCA analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c8692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from ipywidgets import interact, Dropdown, IntSlider\n",
    "from utils import (\n",
    "    categorize_diameter, evaluate_classifier, evaluate_regressor, \n",
    "    plot_confusion_matrix, plot_roc_curves, plot_feature_importance, \n",
    "    ConfusionMatrixDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7060b461",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## 1. Load and Preprocess Profile Data\n",
    "\n",
    "This section defines a function to load and preprocess aortic profile data for PCA analysis. The data is standardized, and clinical labels are matched for further analysis.\n",
    "\n",
    "### Steps:\n",
    "1. Load the selected profile data from CSV files.\n",
    "2. Load clinical labels and categorize aortic diameters into groups:\n",
    "   - `<40mm`\n",
    "   - `40-45mm`\n",
    "   - `45-50mm`\n",
    "   - `≥50mm`\n",
    "3. Standardize the features to ensure they are on the same scale.\n",
    "4. Return the standardized features and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f133853",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68f5986dea342e49a049ff315702fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='profile_type', options=('CenterlineCurvature', 'Diameter', 'Eccent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FILE_PATHS = {\n",
    "    \"CenterlineCurvature\": \"../../Data/measures/AscendingProfile_CenterlineCurvature.csv\",\n",
    "    \"Diameter\": \"../../Data/measures/AscendingProfile_Diameter.csv\",\n",
    "    \"Eccentricity\": \"../../Data/measures/AscendingProfile_Eccentricity.csv\",\n",
    "    \"ScaledDiameter\": \"../../Data/measures/AscendingProfile_ScaledDiameter.csv\"\n",
    "}\n",
    "\n",
    "@interact\n",
    "def load_profile_data(profile_type=Dropdown(options=list(FILE_PATHS.keys()))):\n",
    "    try:\n",
    "        profile_df = pd.read_csv(FILE_PATHS[profile_type])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found for profile type '{profile_type}'.\")\n",
    "        return None, None, profile_type\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: File for profile type '{profile_type}' is empty or invalid.\")\n",
    "        return None, None, profile_type\n",
    "    \n",
    "    # Load labels\n",
    "    ascending_df = pd.read_csv(\"../../Data/measures/Ascending.csv\")\n",
    "    ascending_df['group'] = ascending_df['max_diameter'].apply(categorize_diameter)\n",
    "    id_to_group = dict(zip(ascending_df.iloc[:, 0], ascending_df['group']))\n",
    "    \n",
    "    # Match labels\n",
    "    groups = np.array([id_to_group.get(str(id_value)) for id_value in profile_df.iloc[:, 0]])\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(profile_df.iloc[:, 1:].values)\n",
    "    \n",
    "    return X_scaled, groups, profile_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0d4f4",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## 2. Run PCA Analysis\n",
    "\n",
    "This section performs Principal Component Analysis (PCA) on the standardized data to reduce its dimensionality. PCA identifies the directions (principal components) that capture the most variance in the data.\n",
    "\n",
    "### Outputs:\n",
    "1. A plot showing the cumulative explained variance as a function of the number of components.\n",
    "2. A bar chart showing the variance explained by each principal component.\n",
    "\n",
    "### Parameters:\n",
    "- `n_components`: The number of principal components to retain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d49d025",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_pca_analysis(X_scaled, n_components=10):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Plot explained variance\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_), 'o-')\n",
    "    plt.xlabel(\"Number of Components\")\n",
    "    plt.ylabel(\"Cumulative Explained Variance\")\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.bar(range(n_components), pca.explained_variance_ratio_)\n",
    "    plt.xlabel(\"Principal Component\")\n",
    "    plt.ylabel(\"Variance Explained\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pca, X_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b0c88",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "## 3. Visualize PCA Space\n",
    "\n",
    "This section visualizes the PCA-transformed data in a 2D space using the first two principal components. Each point represents a sample, and the points are color-coded based on their clinical group.\n",
    "\n",
    "### Features:\n",
    "- Scatter plot of PCA-transformed data.\n",
    "- Color-coded groups:\n",
    "  - Blue: `<40mm`\n",
    "  - Green: `40-45mm`\n",
    "  - Orange: `45-50mm`\n",
    "  - Red: `≥50mm`\n",
    "\n",
    "### Parameters:\n",
    "- `pc_x`: The principal component to use for the x-axis.\n",
    "- `pc_y`: The principal component to use for the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0fb6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_space(X_pca, groups, pc_x=0, pc_y=1):\n",
    "    group_colors = {0: \"blue\", 1: \"green\", 2: \"orange\", 3: \"red\"}\n",
    "    group_labels = {0: \"<40mm\", 1: \"40-45mm\", 2: \"45-50mm\", 3: \"≥50mm\"}\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    for group in np.unique(groups):\n",
    "        mask = groups == group\n",
    "        plt.scatter(X_pca[mask, pc_x], X_pca[mask, pc_y],\n",
    "                   c=group_colors[group], label=group_labels[group],\n",
    "                   alpha=0.7)\n",
    "    \n",
    "    plt.xlabel(f\"PC{pc_x+1}\")\n",
    "    plt.ylabel(f\"PC{pc_y+1}\")\n",
    "    plt.title(\"PCA Space\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe0b51",
   "metadata": {},
   "source": [
    "## 4. Evaluate PCA Classification\n",
    "\n",
    "This section evaluates the classification performance of a logistic regression model trained on PCA-transformed features. The model predicts the clinical group of each sample.\n",
    "\n",
    "### Outputs:\n",
    "1. Classification report showing precision, recall, and F1-score for each group.\n",
    "2. Confusion matrix visualizing the model's performance.\n",
    "\n",
    "### Steps:\n",
    "1. Split the PCA-transformed data into training and testing sets.\n",
    "2. Train a logistic regression model on the training set.\n",
    "3. Evaluate the model on the testing set.\n",
    "4. Visualize the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b981072-c9ba-494f-9c2e-e0b3de54f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pca_classification(X_pca, groups):\n",
    "    \"\"\"\n",
    "    Evaluate classification performance using PCA-transformed data.\n",
    "    \n",
    "    Args:\n",
    "        X_pca: PCA-transformed features\n",
    "        groups: True labels\n",
    "    \n",
    "    Returns:\n",
    "        Confusion matrix and classification report\n",
    "    \"\"\"\n",
    "    # Train-test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_pca, groups, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Train a classifier\n",
    "    clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    print(\"Classification Report:\")\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cm, title=\"Confusion Matrix\")\n",
    "    \n",
    "    return cm, report\n",
    "\n",
    "def plot_pca_feature_loadings(pca, feature_names):\n",
    "    loadings = pca.components_.T\n",
    "    num_components = pca.n_components_\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(num_components):\n",
    "        plt.bar(range(len(feature_names)), loadings[:, i], label=f\"PC{i+1}\")\n",
    "    \n",
    "    plt.xticks(range(len(feature_names)), feature_names, rotation=90)\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.ylabel(\"Loadings\")\n",
    "    plt.title(\"PCA Feature Loadings\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def display_variation_modes(pca):\n",
    "    for i, variance in enumerate(pca.explained_variance_ratio_):\n",
    "        print(f\"PC{i+1}: {variance:.2%} of variance explained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69230426",
   "metadata": {},
   "source": [
    "## 5. Interactive PCA Analysis\n",
    "\n",
    "This section provides an interactive interface for PCA analysis using `ipywidgets`. Users can:\n",
    "1. Select the profile type to analyze.\n",
    "2. Adjust the number of principal components (`n_components`).\n",
    "3. Choose which principal components to visualize (`pc_x` and `pc_y`).\n",
    "\n",
    "### Features:\n",
    "- Interactive dropdown to select the profile type.\n",
    "- Sliders to adjust PCA parameters.\n",
    "- Dynamic visualization of PCA space and feature loadings.\n",
    "- Evaluation of classification performance using the selected PCA configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d08c9701-1de2-41a8-99c8-e2f6d6f2c4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b393b17e8a7845849a741ebecaeceb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='profile_type', options=('CenterlineCurvature', 'Diameter', 'Eccent…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact\n",
    "def interactive_pca_combined(profile_type=Dropdown(options=list(FILE_PATHS.keys())),\n",
    "                             n_components=(2, 20, 1), pc_x=(0, 9, 1), pc_y=(1, 10, 1)):\n",
    "    X_scaled, groups, _ = load_profile_data(profile_type)\n",
    "    if X_scaled is None or groups is None:\n",
    "        print(\"Error: Failed to load profile data.\")\n",
    "        return\n",
    "    \n",
    "    pca, X_pca = run_pca_analysis(X_scaled, n_components)\n",
    "    plot_pca_space(X_pca, groups, pc_x, pc_y)\n",
    "    \n",
    "    # Display variation modes\n",
    "    display_variation_modes(pca)\n",
    "    \n",
    "    # Plot PCA feature loadings\n",
    "    feature_df = pd.read_csv(FILE_PATHS[profile_type])\n",
    "    if feature_df.shape[1] > 1:  # Ensure there are feature columns\n",
    "        feature_names = feature_df.columns[1:]\n",
    "        plot_pca_feature_loadings(pca, feature_names)\n",
    "    else:\n",
    "        print(\"No feature columns found in the dataset.\")\n",
    "    \n",
    "    # Evaluate classification performance\n",
    "    cm, report = evaluate_pca_classification(X_pca, groups)\n",
    "    \n",
    "    return pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6632c-9821-415c-9c1f-bc798ad724ca",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we demonstrated the use of PCA for dimensionality reduction on aortic profile data. Key takeaways include:\n",
    "1. PCA effectively reduces the dimensionality of the data while retaining most of the variance.\n",
    "2. Visualizing PCA-transformed data helps identify patterns and group separations.\n",
    "3. PCA-transformed features can be used for classification with reasonable accuracy."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "aorta",
   "language": "python",
   "name": "aorta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
